from sentence_transformers import SentenceTransformer
import requests
from bs4 import BeautifulSoup

# Step 1: URL of the page you want to read
url = "https://docs.nvidia.com/ai-enterprise/workflow/generative-ai/latest/introduction.html"

# Step 2: Fetch the HTML content
response = requests.get(url)
# Check for success
if response.status_code == 200:
    html = response.text

    # Step 3: Parse with BeautifulSoup
    soup = BeautifulSoup(html, 'html.parser')

    # Step 4: Extract readable text (strip scripts, styles, etc.)
    text = soup.get_text(separator=' ', strip=True)

else:
    print(f"Failed to fetch page: {response.status_code}")

import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
from nltk.tokenize import sent_tokenize

sentences = sent_tokenize(text)
print(sentences)
print("--------------------------------- xxxx ----------------------------------")
model = SentenceTransformer("all-MiniLM-L6-v2")
print("Creating embeddings")
embeddings = model.encode(sentences)
print("DONE Creating embeddings")
query = "What is this Document about?"
if query.equals("bye"):
    print("Good Bye! Thanks for using my documentation Analyzer. See you soon")
else :
    print("Initiating search")
    D, I = index.search(np.array(embeddings), k=1)
    print("Most similar sentence:", sentences[I[0][0]])
'''
while True:
    query = input("ASk a question ?: ")
    print(query)
    if query.equals("bye"):
        print("Good Bye! Thanks for using my documentation Analyzer. See you soon")
    else :
        print("Initiating search")
        D, I = index.search(np.array(embeddings), k=1)
        print("Most similar sentence:", sentences[I[0][0]])
'''                  
